# .github/workflows/error-analysis.yml
name: GitHub Actions Error Analysis

on:
  workflow_run:
    workflows: ["CI", "Build", "Test", "Lint", "Deploy", "Test Failure Workflow"]
    types: [completed]

jobs:
  analyze-error:
    if: ${{ github.event.workflow_run.conclusion == 'failure' }}
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      actions: read
      pull-requests: write
      issues: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install dacp
          # Install agent dependencies
          pip install -r agents/github-actions-error-collector/requirements.txt
          pip install -r agents/github-actions-error-analyzer/requirements.txt
        
      - name: Get failed workflow logs
        id: get-logs
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get information about the failed workflow
          echo "Analyzing workflow run ${{ github.event.workflow_run.id }}"
          
          # Create logs directory
          mkdir -p workflow-logs
          
          # Download logs for the failed workflow
          echo "Downloading logs for failed workflow..."
          if gh run download ${{ github.event.workflow_run.id }} \
            --repo ${{ github.repository }} \
            --dir workflow-logs; then
            echo "‚úÖ Log download successful"
          else
            echo "‚ùå Log download failed"
            # Fallback: try to get basic workflow info
            RAW_LOGS="Workflow failed but could not download logs. Workflow: ${{ github.event.workflow_run.name }}, Branch: ${{ github.event.workflow_run.head_branch }}, Commit: ${{ github.event.workflow_run.head_sha }}"
            echo "logs<<EOF" >> $GITHUB_OUTPUT
            echo "$RAW_LOGS" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # List downloaded files for debugging
          echo "Downloaded files:"
          find workflow-logs -type f | head -10
          
          # Process logs - look for error patterns
          echo "Extracting error information from logs..."
          
          # Create a temporary file for processed logs
          TEMP_LOG_FILE="processed-logs.txt"
          touch "$TEMP_LOG_FILE"
          
          # Process each log file
          find workflow-logs -name "*.txt" -type f | while read -r logfile; do
            echo "Processing: $logfile"
            
            # Check if file contains errors
            if grep -q -i "error\|fail\|exception\|fatal\|panic\|abort" "$logfile" 2>/dev/null; then
              echo "=== ERRORS FROM: $(basename "$logfile") ===" >> "$TEMP_LOG_FILE"
              # Extract lines around errors
              grep -B 2 -A 5 -i "error\|fail\|exception\|fatal" "$logfile" | head -50 >> "$TEMP_LOG_FILE" 2>/dev/null || true
              echo -e "\n" >> "$TEMP_LOG_FILE"
            fi
          done
          
          # If no errors found, get the last part of the most recent log file
          if [ ! -s "$TEMP_LOG_FILE" ]; then
            echo "No obvious error patterns found, getting log tails..."
            MOST_RECENT_LOG=$(find workflow-logs -name "*.txt" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2-)
            if [ -n "$MOST_RECENT_LOG" ] && [ -f "$MOST_RECENT_LOG" ]; then
              echo "=== TAIL OF: $(basename "$MOST_RECENT_LOG") ===" >> "$TEMP_LOG_FILE"
              tail -100 "$MOST_RECENT_LOG" >> "$TEMP_LOG_FILE" 2>/dev/null || true
            fi
          fi
          
          # Read processed logs
          if [ -s "$TEMP_LOG_FILE" ]; then
            RAW_LOGS=$(cat "$TEMP_LOG_FILE")
            echo "‚úÖ Successfully extracted logs (${#RAW_LOGS} characters)"
          else
            RAW_LOGS="Failed to extract error information from logs. No error patterns found in downloaded logs."
            echo "‚ùå No error patterns found in logs"
          fi
          
          # Clean up temp file
          rm -f "$TEMP_LOG_FILE"
          
          # Limit output size (GitHub Actions variable limit)
          MAX_SIZE=30000
          if [ ${#RAW_LOGS} -gt $MAX_SIZE ]; then
            echo "logs=${RAW_LOGS:0:$MAX_SIZE}... [TRUNCATED - Original size: ${#RAW_LOGS} chars]" >> $GITHUB_OUTPUT
            echo "Log truncated due to size (${#RAW_LOGS} > $MAX_SIZE chars)"
          else
            echo "logs<<EOF" >> $GITHUB_OUTPUT
            echo "$RAW_LOGS" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            echo "Log extraction completed (${#RAW_LOGS} chars)"
          fi
          
      - name: Run DACP error analysis
        id: analysis
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          echo "Running DACP error analysis..."
          
          # Get PR number if available
          PR_NUMBER=""
          if [ "${{ github.event.workflow_run.event }}" = "pull_request" ] && [ -n "${{ github.event.workflow_run.pull_requests[0].number }}" ]; then
            PR_NUMBER="${{ github.event.workflow_run.pull_requests[0].number }}"
          fi
          
          # Run the DACP workflow
          dacp run workflow agents/github-actions-error-workflow.yaml \
            --workflow-name quick_error_analysis \
            --input job_name="${{ github.event.workflow_run.name }}" \
            --input workflow_name="${{ github.event.workflow_run.name }}" \
            --input raw_logs="${{ steps.get-logs.outputs.logs }}" \
            --input repository="${{ github.repository }}" \
            --input branch="${{ github.event.workflow_run.head_branch }}" \
            --input commit_sha="${{ github.event.workflow_run.head_sha }}" \
            --input pr_number="$PR_NUMBER" \
            --output analysis-results.json
          
          echo "Analysis completed successfully"
          
      - name: Process analysis results
        if: always()
        run: |
          if [ -f analysis-results.json ]; then
            echo "Analysis results:"
            cat analysis-results.json | jq '.'
            
            # Extract key information for summary
            ROOT_CAUSE=$(cat analysis-results.json | jq -r '.context.output.analysis_result.root_cause // "Unknown"')
            CATEGORY=$(cat analysis-results.json | jq -r '.context.output.analysis_result.error_category // "Unknown"')
            SUMMARY=$(cat analysis-results.json | jq -r '.context.output.developer_message.summary // "No summary available"')
            
            echo "ROOT_CAUSE=$ROOT_CAUSE" >> $GITHUB_ENV
            echo "CATEGORY=$CATEGORY" >> $GITHUB_ENV
            echo "SUMMARY=$SUMMARY" >> $GITHUB_ENV
          else
            echo "No analysis results found"
          fi
          
      - name: Comment on PR (if applicable)
        if: github.event.workflow_run.event == 'pull_request' && github.event.workflow_run.pull_requests[0].number
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let analysisComment = "## ü§ñ AI Error Analysis\n\n";
            
            if (fs.existsSync('analysis-results.json')) {
              const results = JSON.parse(fs.readFileSync('analysis-results.json', 'utf8'));
              const output = results.context?.output;
              
              if (output) {
                analysisComment += `**Error Category:** ${output.analysis_result?.error_category || 'Unknown'}\n`;
                analysisComment += `**Root Cause:** ${output.analysis_result?.root_cause || 'Unknown'}\n`;
                analysisComment += `**Confidence:** ${output.analysis_result?.confidence_level || 'Unknown'}\n\n`;
                
                analysisComment += `### üí¨ Summary\n${output.developer_message?.summary || 'No summary available'}\n\n`;
                
                if (output.recommended_fixes && output.recommended_fixes.length > 0) {
                  analysisComment += `### üîß Recommended Fixes\n`;
                  output.recommended_fixes.forEach((fix, index) => {
                    analysisComment += `${index + 1}. **${fix.fix_title}**\n`;
                    analysisComment += `   - ${fix.fix_description}\n`;
                    analysisComment += `   - Effort: ${fix.estimated_effort}\n\n`;
                  });
                }
                
                if (output.developer_message?.next_steps) {
                  analysisComment += `### üìã Next Steps\n`;
                  output.developer_message.next_steps.forEach((step, index) => {
                    analysisComment += `${index + 1}. ${step}\n`;
                  });
                }
              } else {
                analysisComment += "Analysis completed but no detailed results available.";
              }
            } else {
              analysisComment += "‚ùå Analysis failed or no results generated.";
            }
            
            await github.rest.issues.createComment({
              issue_number: ${{ github.event.workflow_run.pull_requests[0].number }},
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: analysisComment
            });
            
      - name: Upload analysis results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: error-analysis-results
          path: |
            analysis-results.json
            workflow-logs/
          retention-days: 30